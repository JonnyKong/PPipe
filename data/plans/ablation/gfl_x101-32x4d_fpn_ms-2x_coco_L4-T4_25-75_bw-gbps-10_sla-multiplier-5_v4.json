[
  {
    "xput": 2466.5177532591483,
    "config": {
      "dnn_name": "gfl_x101-32x4d_fpn_ms-2x_coco",
      "gpu_name_arr": [
        "L4",
        "T4"
      ],
      "sla": 99947.1468253968,
      "num_mps_levels": [
        4,
        4
      ],
      "max_num_parts": 3,
      "bs_same": true,
      "transmit_time_us_arr": [
        10485.76,
        5242.88,
        6553.599999999999,
        7864.32,
        7864.32,
        3440.64,
        6113.28,
        2385.92
      ],
      "est_xput": 2341.36346584861,
      "batch_build_factor": 1.3,
      "hist_adjustment": 9995,
      "hist_adjustment_w_scheduling": 0,
      "num_gpu_per_server_arr": [
        4,
        2
      ],
      "force_sum_gpu_integer_per_partition": true,
      "bw_gbps": 10,
      "runtime_fmt": 1
    },
    "sla": 99947.1468253968,
    "pipelines": [
      {
        "xput": 1604.7243083638566,
        "partitions": [
          {
            "dnn": "gfl_x101-32x4d_fpn_ms-2x_coco",
            "layers": [
              0,
              8
            ],
            "gpu": "L4",
            "mps": 0,
            "bs": 2,
            "num_gpu_per_server": 4,
            "num_gpu": 25.0,
            "lat_infer": 31158.0,
            "lat_trans": 4771.84,
            "xput": 1604.7243083638232
          },
          {
            "dnn": "gfl_x101-32x4d_fpn_ms-2x_coco",
            "layers": [
              8,
              9
            ],
            "gpu": "T4",
            "mps": 1,
            "bs": 2,
            "num_gpu_per_server": 2,
            "num_gpu": 13.5,
            "lat_infer": 33037.0,
            "lat_trans": 0.0,
            "xput": 1634.5309804158974
          }
        ],
        "est_xput": 2341.36346584861,
        "est_batch_build_lat": 555.2320342236247,
        "batch_build_factor": 1.3,
        "hist_adjustment": 9995,
        "hist_adjustment_w_scheduling": 0
      },
      {
        "xput": 26.89067372765332,
        "partitions": [
          {
            "dnn": "gfl_x101-32x4d_fpn_ms-2x_coco",
            "layers": [
              0,
              9
            ],
            "gpu": "T4",
            "mps": 0,
            "bs": 1,
            "num_gpu_per_server": 2,
            "num_gpu": 1.9999938586699437,
            "lat_infer": 74375.0,
            "lat_trans": 0.0,
            "xput": 26.89067373001605
          }
        ],
        "est_xput": 2341.36346584861,
        "est_batch_build_lat": 0.0,
        "batch_build_factor": 1.3,
        "hist_adjustment": 9995,
        "hist_adjustment_w_scheduling": 0
      },
      {
        "xput": 834.9021854792226,
        "partitions": [
          {
            "dnn": "gfl_x101-32x4d_fpn_ms-2x_coco",
            "layers": [
              0,
              8
            ],
            "gpu": "T4",
            "mps": 0,
            "bs": 1,
            "num_gpu_per_server": 2,
            "num_gpu": 51.0,
            "lat_infer": 61085.0,
            "lat_trans": 2385.92,
            "xput": 834.9021854792502
          },
          {
            "dnn": "gfl_x101-32x4d_fpn_ms-2x_coco",
            "layers": [
              8,
              9
            ],
            "gpu": "T4",
            "mps": 1,
            "bs": 1,
            "num_gpu_per_server": 2,
            "num_gpu": 8.5,
            "lat_infer": 20225.0,
            "lat_trans": 0.0,
            "xput": 840.5438813349815
          }
        ],
        "est_xput": 2341.36346584861,
        "est_batch_build_lat": 0.0,
        "batch_build_factor": 1.3,
        "hist_adjustment": 9995,
        "hist_adjustment_w_scheduling": 0
      }
    ],
    "mipgap": 0.07261071749667533,
    "runtime": 1800.1593842506409
  }
]