[
  {
    "xput": 826.5327460234624,
    "config": {
      "dnn_name": "efficientnet-b8_3rdparty_8xb32-aa-advprop_in1k",
      "gpu_name_arr": [
        "L4",
        "T4"
      ],
      "sla": 165577.24836601308,
      "num_mps_levels": [
        4,
        4
      ],
      "max_num_parts": 2,
      "bs_same": true,
      "transmit_time_us_arr": [
        5780.2752,
        2528.8704000000002,
        2528.8704000000002,
        2528.8704000000002,
        993.4848000000001,
        496.74240000000003,
        496.74240000000003,
        699.9552,
        299.1744
      ],
      "est_xput": 896.2883838569867,
      "batch_build_factor": 1.3,
      "hist_adjustment": 66231,
      "hist_adjustment_w_scheduling": 0,
      "num_gpu_per_server_arr": [
        4,
        2
      ],
      "force_sum_gpu_integer_per_partition": true,
      "bw_gbps": 10,
      "runtime_fmt": 1
    },
    "sla": 165577.24836601308,
    "pipelines": [
      {
        "xput": 642.3638991488679,
        "partitions": [
          {
            "dnn": "efficientnet-b8_3rdparty_8xb32-aa-advprop_in1k",
            "layers": [
              0,
              9
            ],
            "gpu": "T4",
            "mps": 0,
            "bs": 1,
            "num_gpu_per_server": 2,
            "num_gpu": 43.0,
            "lat_infer": 66717.0,
            "lat_trans": 299.1744,
            "xput": 644.5133923887465
          },
          {
            "dnn": "efficientnet-b8_3rdparty_8xb32-aa-advprop_in1k",
            "layers": [
              9,
              10
            ],
            "gpu": "L4",
            "mps": 1,
            "bs": 1,
            "num_gpu_per_server": 4,
            "num_gpu": 2.0,
            "lat_infer": 6227.0,
            "lat_trans": 0.0,
            "xput": 642.3638991488679
          }
        ],
        "est_xput": 896.2883838569867,
        "est_batch_build_lat": 0.0,
        "batch_build_factor": 1.3,
        "hist_adjustment": 66231,
        "hist_adjustment_w_scheduling": 0
      },
      {
        "xput": 184.16884687459458,
        "partitions": [
          {
            "dnn": "efficientnet-b8_3rdparty_8xb32-aa-advprop_in1k",
            "layers": [
              0,
              10
            ],
            "gpu": "T4",
            "mps": 0,
            "bs": 1,
            "num_gpu_per_server": 2,
            "num_gpu": 15.000000071123615,
            "lat_infer": 81447.0,
            "lat_trans": 0.0,
            "xput": 184.16884687126125
          }
        ],
        "est_xput": 896.2883838569867,
        "est_batch_build_lat": 0.0,
        "batch_build_factor": 1.3,
        "hist_adjustment": 66231,
        "hist_adjustment_w_scheduling": 0
      }
    ],
    "mipgap": 0.019921257945362897,
    "runtime": 60.128928899765015
  },
  {
    "xput": 551.0218306808276,
    "config": {
      "dnn_name": "encnet_r101-d8_4xb2-40k_cityscapes-512x1024",
      "gpu_name_arr": [
        "L4",
        "T4"
      ],
      "sla": 87047.44982698961,
      "num_mps_levels": [
        4,
        4
      ],
      "max_num_parts": 2,
      "bs_same": true,
      "transmit_time_us_arr": [
        1677.7216,
        3355.4432,
        3355.4432,
        3355.4432,
        3355.4432,
        3355.4432,
        6710.8864,
        1677.7216,
        109051.90400000001
      ],
      "est_xput": 410.74187806833964,
      "batch_build_factor": 1.3,
      "hist_adjustment": 34819,
      "hist_adjustment_w_scheduling": 0,
      "num_gpu_per_server_arr": [
        4,
        2
      ],
      "force_sum_gpu_integer_per_partition": true,
      "bw_gbps": 10,
      "runtime_fmt": 1
    },
    "sla": 87047.44982698961,
    "pipelines": [
      {
        "xput": 551.0218306808276,
        "partitions": [
          {
            "dnn": "encnet_r101-d8_4xb2-40k_cityscapes-512x1024",
            "layers": [
              0,
              8
            ],
            "gpu": "L4",
            "mps": 0,
            "bs": 2,
            "num_gpu_per_server": 4,
            "num_gpu": 7.0,
            "lat_infer": 23405.0,
            "lat_trans": 3355.4432,
            "xput": 598.162785729545
          },
          {
            "dnn": "encnet_r101-d8_4xb2-40k_cityscapes-512x1024",
            "layers": [
              8,
              10
            ],
            "gpu": "T4",
            "mps": 0,
            "bs": 2,
            "num_gpu_per_server": 2,
            "num_gpu": 4.0,
            "lat_infer": 14007.0,
            "lat_trans": 0.0,
            "xput": 571.1429999286071
          }
        ],
        "est_xput": 410.74187806833964,
        "est_batch_build_lat": 3165.004761904762,
        "batch_build_factor": 1.3,
        "hist_adjustment": 34819,
        "hist_adjustment_w_scheduling": 0
      }
    ]
  },
  {
    "xput": 750.9892839606019,
    "config": {
      "dnn_name": "rtmdet_x_8xb32-300e_coco",
      "gpu_name_arr": [
        "L4",
        "T4"
      ],
      "sla": 117736.42093023255,
      "num_mps_levels": [
        4,
        4
      ],
      "max_num_parts": 2,
      "bs_same": true,
      "transmit_time_us_arr": [
        6553.599999999999,
        6553.599999999999,
        3276.7999999999997,
        3276.7999999999997,
        5734.4,
        4505.6,
        5734.4,
        5120.0,
        1128.96
      ],
      "est_xput": 553.3098688963005,
      "batch_build_factor": 1.3,
      "hist_adjustment": 47095,
      "hist_adjustment_w_scheduling": 0,
      "num_gpu_per_server_arr": [
        4,
        2
      ],
      "force_sum_gpu_integer_per_partition": true,
      "bw_gbps": 10,
      "runtime_fmt": 1
    },
    "sla": 117736.42093023255,
    "pipelines": [
      {
        "xput": 750.9892839606019,
        "partitions": [
          {
            "dnn": "rtmdet_x_8xb32-300e_coco",
            "layers": [
              0,
              9
            ],
            "gpu": "L4",
            "mps": 0,
            "bs": 1,
            "num_gpu_per_server": 4,
            "num_gpu": 16.0,
            "lat_infer": 21149.0,
            "lat_trans": 1128.96,
            "xput": 756.5369521017542
          },
          {
            "dnn": "rtmdet_x_8xb32-300e_coco",
            "layers": [
              9,
              10
            ],
            "gpu": "T4",
            "mps": 1,
            "bs": 1,
            "num_gpu_per_server": 2,
            "num_gpu": 13.0,
            "lat_infer": 34621.0,
            "lat_trans": 0.0,
            "xput": 750.9892839606019
          }
        ],
        "est_xput": 553.3098688963005,
        "est_batch_build_lat": 0.0,
        "batch_build_factor": 1.3,
        "hist_adjustment": 47095,
        "hist_adjustment_w_scheduling": 0
      }
    ]
  }
]