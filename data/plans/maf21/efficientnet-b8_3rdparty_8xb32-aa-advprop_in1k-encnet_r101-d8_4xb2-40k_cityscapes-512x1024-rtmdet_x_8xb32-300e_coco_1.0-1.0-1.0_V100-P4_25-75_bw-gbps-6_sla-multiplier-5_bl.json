[
  {
    "xput": 381.7249194798998,
    "config": {
      "dnn_name": "efficientnet-b8_3rdparty_8xb32-aa-advprop_in1k",
      "gpu_name_arr": [
        "V100",
        "P4"
      ],
      "sla": 165577.24836601308,
      "num_mps_levels": [
        1,
        1
      ],
      "max_num_parts": 1,
      "bs_same": true,
      "transmit_time_us_arr": [
        9633.792000000001,
        4214.784,
        4214.784,
        4214.784,
        1655.808,
        827.904,
        827.904,
        1166.5919999999999,
        498.624
      ],
      "est_xput": 381.7249194798998,
      "batch_build_factor": 1.3,
      "hist_adjustment": 66231,
      "hist_adjustment_w_scheduling": 0,
      "num_gpu_per_server_arr": [
        2,
        1
      ],
      "force_sum_gpu_integer_per_partition": true,
      "bw_gbps": 6,
      "runtime_fmt": 1
    },
    "sla": 165577.24836601308,
    "pipelines": [
      {
        "xput": 381.7249194798998,
        "partitions": [
          {
            "dnn": "efficientnet-b8_3rdparty_8xb32-aa-advprop_in1k",
            "layers": [
              0,
              10
            ],
            "gpu": "V100",
            "mps": 0,
            "bs": 4,
            "num_gpu_per_server": 2,
            "num_gpu": 8.0,
            "lat_infer": 83830.0,
            "lat_trans": 0.0,
            "xput": 381.7249194798998
          }
        ],
        "est_xput": 381.7249194798998,
        "est_batch_build_lat": 10216.781249999998,
        "batch_build_factor": 1.3,
        "hist_adjustment": 66231,
        "hist_adjustment_w_scheduling": 0
      }
    ],
    "mipgap": 0.0,
    "runtime": 0.0619816780090332
  },
  {
    "xput": 379.6404262819643,
    "config": {
      "dnn_name": "encnet_r101-d8_4xb2-40k_cityscapes-512x1024",
      "gpu_name_arr": [
        "V100",
        "P4"
      ],
      "sla": 87047.44982698961,
      "num_mps_levels": [
        1,
        1
      ],
      "max_num_parts": 1,
      "bs_same": true,
      "transmit_time_us_arr": [
        2796.2026666666666,
        5592.405333333333,
        5592.405333333333,
        5592.405333333333,
        5592.405333333333,
        5592.405333333333,
        11184.810666666666,
        2796.2026666666666,
        181753.1733333333
      ],
      "est_xput": 416.8320762207225,
      "batch_build_factor": 1.3,
      "hist_adjustment": 34819,
      "hist_adjustment_w_scheduling": 0,
      "num_gpu_per_server_arr": [
        2,
        1
      ],
      "force_sum_gpu_integer_per_partition": true,
      "bw_gbps": 6,
      "runtime_fmt": 1
    },
    "sla": 87047.44982698961,
    "pipelines": [
      {
        "xput": 379.6404262819643,
        "partitions": [
          {
            "dnn": "encnet_r101-d8_4xb2-40k_cityscapes-512x1024",
            "layers": [
              0,
              10
            ],
            "gpu": "V100",
            "mps": 0,
            "bs": 2,
            "num_gpu_per_server": 2,
            "num_gpu": 7.0,
            "lat_infer": 36877.0,
            "lat_trans": 0.0,
            "xput": 379.6404262819643
          }
        ],
        "est_xput": 416.8320762207225,
        "est_batch_build_lat": 3118.761904761905,
        "batch_build_factor": 1.3,
        "hist_adjustment": 34819,
        "hist_adjustment_w_scheduling": 0
      }
    ]
  },
  {
    "xput": 363.8149637094574,
    "config": {
      "dnn_name": "rtmdet_x_8xb32-300e_coco",
      "gpu_name_arr": [
        "V100",
        "P4"
      ],
      "sla": 117736.42093023255,
      "num_mps_levels": [
        1,
        1
      ],
      "max_num_parts": 1,
      "bs_same": true,
      "transmit_time_us_arr": [
        10922.666666666668,
        10922.666666666668,
        5461.333333333334,
        5461.333333333334,
        9557.333333333332,
        7509.333333333333,
        9557.333333333332,
        8533.333333333334,
        1881.6
      ],
      "est_xput": 363.8149637094574,
      "batch_build_factor": 1.3,
      "hist_adjustment": 47095,
      "hist_adjustment_w_scheduling": 0,
      "num_gpu_per_server_arr": [
        2,
        1
      ],
      "force_sum_gpu_integer_per_partition": true,
      "bw_gbps": 6,
      "runtime_fmt": 1
    },
    "sla": 117736.42093023255,
    "pipelines": [
      {
        "xput": 363.8149637094574,
        "partitions": [
          {
            "dnn": "rtmdet_x_8xb32-300e_coco",
            "layers": [
              0,
              10
            ],
            "gpu": "V100",
            "mps": 0,
            "bs": 2,
            "num_gpu_per_server": 2,
            "num_gpu": 10.0,
            "lat_infer": 54973.0,
            "lat_trans": 0.0,
            "xput": 363.8149637094574
          }
        ],
        "est_xput": 363.8149637094574,
        "est_batch_build_lat": 3573.2449999999994,
        "batch_build_factor": 1.3,
        "hist_adjustment": 47095,
        "hist_adjustment_w_scheduling": 0
      }
    ]
  }
]